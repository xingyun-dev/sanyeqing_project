{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三叶青分类-ONNX Runtime部署-视频\n",
    "\n",
    "使用 ONNX Runtime 推理引擎，载入自己训练得到的图像分类 onnx 模型，预测摄像头实时画面。\n",
    "\n",
    "2024/5/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cf0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(r'D:\\Train_Custom_Dataset\\图像分类\\7-ONNX Runtime图像分类部署\\1-Pytorch图像分类模型转ONNX\\resnet101_sanyeqing_10.onnx')\n",
    "#测试时，我们只使用确定性的图像预处理操作\n",
    "transform_test = transforms.Compose([transforms.Resize(256),\n",
    "                                    # 从图像中心裁切224x224大小的图片\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                        [0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理单帧画面的函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理帧函数\n",
    "def process_frame(img,n,idx_to_labels_csv):\n",
    "    \n",
    "    '''\n",
    "    输入摄像头拍摄画面bgr-array，输出图像分类预测结果bgr-array\n",
    "    '''\n",
    "    \n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## 画面转成 RGB 的 Pillow 格式\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR转RGB\n",
    "    img_pil = Image.fromarray(img_rgb) # array 转 PIL\n",
    "\n",
    "    ## 预处理\n",
    "    input_img = transform_test(img_pil) # 预处理\n",
    "    input_tensor = input_img.unsqueeze(0).numpy()\n",
    "    \n",
    "    ## onnx runtime 预测\n",
    "    ort_inputs = {'input': input_tensor} # onnx runtime 输入\n",
    "    pred_logits = ort_session.run(['output'], ort_inputs)[0] # onnx runtime 输出\n",
    "    pred_logits = torch.tensor(pred_logits)\n",
    "    pred_softmax = F.softmax(pred_logits, dim=1) # 对 logit 分数做 softmax 运算\n",
    "    \n",
    "    # 载入类别和对应 ID\n",
    "    idx_to_labels = pd.read_csv(idx_to_labels_csv,encoding='utf-8')\n",
    "    # 创建一个字典来存储真实标签\n",
    "    idx_to_labels = {str(index): row['labels'] for index, row in idx_to_labels.iterrows()}  \n",
    "\n",
    "    ## 解析top-n预测结果的类别和置信度\n",
    "    top_n = torch.topk(pred_softmax, n) # 取置信度最大的 n 个结果\n",
    "    pred_ids = top_n[1].cpu().detach().numpy().squeeze() # 解析出类别\n",
    "    confs = top_n[0].cpu().detach().numpy().squeeze() # 解析出置信度\n",
    "    \n",
    "    ## 在图像上写中文\n",
    "    draw = ImageDraw.Draw(img_pil) \n",
    "    for i in range(len(confs)):\n",
    "        class_name = idx_to_labels[str(pred_ids[i])] # 获取类别名称\n",
    "        text = '{:<15} {:>.3f}'.format(class_name, confs[i])\n",
    "        # 文字坐标，中文字符串，字体，rgba颜色\n",
    "        draw.text((50, 100 + 50 * i), text, fill=(255, 0, 0, 1))\n",
    "    img = np.array(img_pil) # PIL 转 array\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # RGB转BGR\n",
    "    \n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)  \n",
    "    # 图片，添加的文字，左上角坐标，字体，字体大小，颜色，线宽，线型\n",
    "    img = cv2.putText(img, 'FPS  '+str(int(FPS)), (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 255), 4, cv2.LINE_AA)\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用摄像头获取每帧（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用摄像头逐帧实时处理模板\n",
    "# 导入opencv-python\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 打开cap\n",
    "cap.open(0)\n",
    "\n",
    "# 无限循环，直到break被触发\n",
    "while cap.isOpened():\n",
    "    # 获取画面\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    ## !!!处理帧函数\n",
    "    frame = process_frame(frame,5,idx_to_labels_csv=\"D:\\三叶青项目\\wht-sanyeqing\\idx_to_labels.csv\")\n",
    "    \n",
    "    # 展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "\n",
    "    if cv2.waitKey(1) in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "        break\n",
    "    \n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按键盘上的`q`键退出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 视频逐帧处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_video(input_path,n,idx_to_labels_csv):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    \n",
    "    print('视频开始处理',input_path)\n",
    "    \n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为',frame_count)\n",
    "    \n",
    "    # cv2.namedWindow('Crack Detection and Measurement Video Processing')\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    \n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count-1) as pbar:\n",
    "        try:\n",
    "            while(cap.isOpened()):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                # # 处理帧\n",
    "                # frame_path = './temp_frame.png'\n",
    "                # cv2.imwrite(frame_path, frame)\n",
    "                try:\n",
    "                    frame = process_frame(frame,n,idx_to_labels_csv)\n",
    "                except:\n",
    "                    print('报错！', error)\n",
    "                    pass\n",
    "                \n",
    "                if success == True:\n",
    "                    cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频开始处理 D:/vedio/2024-05-03-01-17-14.mp4\n",
      "视频总帧数为 684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 683/683 [02:09<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频已保存 out-2024-05-03-01-17-14.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_video(input_path=r\"D:/vedio/2024-05-03-01-17-14.mp4\",n=5,idx_to_labels_csv=\"D:\\三叶青项目\\wht-sanyeqing\\idx_to_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
