{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch模型部署（补充）\n",
    "\n",
    "不将.pth模型文件转化为onnx模型文件，而是直接部署pytorch模型文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import onnxruntime\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "# 调用摄像头逐帧实时处理模板\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def load_model_and_labels(model_path, labels_json_path):\n",
    "    # 检查模型文件的扩展名\n",
    "    _, ext = os.path.splitext(model_path)\n",
    "    if ext == '.onnx':\n",
    "        # 加载 onnx 模型\n",
    "        model = onnxruntime.InferenceSession(model_path)\n",
    "    elif ext == '.pth':\n",
    "        # 加载 PyTorch 模型\n",
    "        model = torch.load(model_path, map_location=device)  # 或者使用 torch.load，取决于你的模型是如何保存的\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model file extension\")\n",
    "\n",
    "    # 加载标签\n",
    "    with open(labels_json_path, 'r', encoding='utf-8') as f:\n",
    "        labels = json.load(f)\n",
    "\n",
    "    return model, labels\n",
    "\n",
    "\n",
    "\n",
    "# 测试时，我们只使用确定性的图像预处理操作\n",
    "transform_test = transforms.Compose([transforms.Resize(256),\n",
    "                                     # 从图像中心裁切224x224大小的图片\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "\n",
    "# 处理帧函数\n",
    "def process_frame(img, n, ort_session, labels):\n",
    "    '''\n",
    "    输入摄像头拍摄画面bgr-array，输出图像分类预测结果bgr-array\n",
    "    '''\n",
    "\n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    ## 画面转成 RGB 的 Pillow 格式\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR转RGB\n",
    "    img_pil = Image.fromarray(img_rgb)  # array 转 PIL\n",
    "\n",
    "    ## 预处理\n",
    "    input_img = transform_test(img_pil)  # 预处理\n",
    "    # input_tensor = input_img.unsqueeze(0).numpy()\n",
    "    input_tensor = input_img.unsqueeze(0)\n",
    "    ## 判断模型类型并进行预测\n",
    "    if isinstance(ort_session, torch.nn.Module):\n",
    "        # 使用 PyTorch 进行预测\n",
    "        with torch.no_grad():\n",
    "            ort_session.eval()\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            pred_logits = ort_session(input_tensor)\n",
    "            pred_softmax = F.softmax(pred_logits, dim=1)  # 对 logit 分数做 softmax 运算\n",
    "    elif isinstance(ort_session, onnxruntime.InferenceSession):\n",
    "        # 使用 ONNX Runtime 进行预测\n",
    "        input_tensor = input_tensor.numpy()\n",
    "        ort_inputs = {'input': input_tensor}  # onnx runtime 输入\n",
    "        pred_logits = ort_session.run(['output'], ort_inputs)[0]  # onnx runtime 输出\n",
    "        pred_logits = torch.tensor(pred_logits)\n",
    "        pred_softmax = F.softmax(pred_logits, dim=1)  # 对 logit 分数做 softmax 运算\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "    #\n",
    "    # 获取类别的数量\n",
    "    num_classes = n\n",
    "\n",
    "    # 如果类别数小于等于11，则显示所有类别，否则只显示前11个\n",
    "    if num_classes <= 11:\n",
    "        top_n = torch.sort(pred_softmax, descending=True)\n",
    "    else:\n",
    "        top_n = torch.topk(pred_softmax, 11)  # 取置信度最大的 11 个结果\n",
    "    pred_ids = top_n[1].cpu().detach().numpy().squeeze()  # 解析出类别\n",
    "    confs = top_n[0].cpu().detach().numpy().squeeze()  # 解析出置信度\n",
    "\n",
    "    from PIL import ImageFont\n",
    "\n",
    "    # 加载字体，第二个参数是字体大小\n",
    "    font = ImageFont.truetype('simsun.ttc', 15)\n",
    "\n",
    "    ## 在图像上写中文\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    # 获取类别的数量\n",
    "    num_classes = len(confs)\n",
    "\n",
    "    # 如果类别数小于等于11，则显示所有类别，否则只显示前11个\n",
    "    if num_classes <= 11:\n",
    "        display_classes = num_classes\n",
    "    else:\n",
    "        display_classes = 11\n",
    "\n",
    "    for i in range(display_classes):\n",
    "        class_name = labels[str(pred_ids[i])]  # 获取类别名称\n",
    "        text = '{:<15} {:>.3f}'.format(class_name, confs[i])\n",
    "        # 文字坐标，中文字符串，字体，rgba颜色\n",
    "        draw.text((50, 100 + 30 * i), text, fill=(255,0 ,255 , 1), font=font)\n",
    "    img = np.array(img_pil)  # PIL 转 array\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # RGB转BGR\n",
    "\n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1 / (end_time - start_time)\n",
    "    # 图片，添加的文字，左上角坐标，字体，字体大小，颜色，线宽，线型\n",
    "    img = cv2.putText(img, 'FPS  ' + str(int(FPS)), (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 255), 4,\n",
    "                      cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_video(input_path, n, ort_session,labels):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    #\n",
    "    # print('视频开始处理', input_path)\n",
    "\n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    # print('视频总帧数为', frame_count)\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    # print(cap)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    # print(out)\n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count - 1) as pbar:\n",
    "        try:\n",
    "            while cap.isOpened():\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "                try:\n",
    "                    frame = process_frame(img=frame, n=n, ort_session=ort_session, labels=labels)\n",
    "                except:\n",
    "                    print('报错！', os.error)\n",
    "                    pass\n",
    "\n",
    "                if success == True:\n",
    "                    cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    weights_path = r\"D:\\SanYeQing_Project\\wht_sanyeqing_image-Classification\\model_zheng_path\\model_cpu_97.18.pth\"\n",
    "    class_json_path = r\"D:\\SanYeQing_Project\\wht_sanyeqing_image-Classification\\【4】在测试集上评估模型精度\\class_5.json\"\n",
    "    assert os.path.exists(weights_path), \"weights path does not exist...\"\n",
    "    assert os.path.exists(class_json_path), \"class json path does not exist...\"\n",
    "\n",
    "\n",
    "    # 加载初始模型和标签\n",
    "    ort_session, labels = load_model_and_labels(weights_path, class_json_path)\n",
    "    # 获取摄像头，传入0表示获取系统默认摄像头\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # 打开cap\n",
    "    cap.open(0)\n",
    "    # # 无限循环，直到break被触发\n",
    "    while cap.isOpened():\n",
    "        # 获取画面\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print('Error')\n",
    "            break\n",
    "    \n",
    "            # 使用当前模型和标签处理帧\n",
    "        frame = process_frame(frame, 11, ort_session, labels)\n",
    "    \n",
    "        # 展示处理后的三通道图像\n",
    "        cv2.imshow('my_window', frame)\n",
    "        \n",
    "        # 如果用户长按下 '1'，则切换到模型1和标签1\n",
    "        if cv2.waitKey(1) == ord('a'):\n",
    "            ort_session, labels = load_model_and_labels(weights_path, class_json_path)\n",
    "        \n",
    "        # 如果用户长按下 '2'，则切换到模型2和标签2\n",
    "        elif cv2.waitKey(1) == ord('s'):\n",
    "            ort_session, labels = load_model_and_labels('D:\\SanYeQing_Project\\wht_sanyeqing_image-Classification\\onnx_path\\model_cpu_97.18.onnx',class_json_path)\n",
    "        \n",
    "        # # 如果用户长按下 '3'，则切换到模型3和标签3\n",
    "        # elif cv2.waitKey(1) == ord('d'):\n",
    "        #     ort_session, labels = load_model_and_labels('./model_cpu_11.onnx', './class_indices_10.json')\n",
    "        \n",
    "        # 如果用户长按下 'q' 或 'esc'，则退出循环\n",
    "        elif cv2.waitKey(1) in [ord('q'), 27]:\n",
    "            break\n",
    "    # 关闭摄像头\n",
    "    cap.release()\n",
    "    # 关闭图像窗口\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
